2025-06-23 17:26:25
Args in experiment:
Namespace(train_only=False, wo_test=False, wo_valid=False, only_test=False, do_valid=False, model='iTransformer', override_hyper=True, compile=False, reduce_bs=False, normalization=None, checkpoints='./checkpoints/', tag='', online_method='Proceed', skip='logs/online/iTransformer_Proceed_mid50_share_fulltune_down_up_ETTh2_48_btl48_lr0.003_onlinelr0.00003.log', online_learning_rate=3e-05, val_online_lr=True, diff_online_lr=True, save_opt=True, leakage=False, debug=False, pretrain=True, freeze=False, act='sigmoid', tune_mode='down_up', ema=0, concept_dim=50, bottleneck_dim=48, individual_generator=False, share_encoder=False, use_mean=True, joint_update_valid=False, comment='', wo_clip=False, learning_rate_w=0.001, learning_rate_bias=0.001, border_type='online', root_path='./dataset/', dataset='ETTh2', features='M', target='OT', freq='h', wrap_data_class=[], pin_gpu=True, use_time=False, seq_len=336, label_len=48, pred_len=48, individual=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, drop_last=False, embed_type=0, d_model=128, n_heads=8, e_layers=2, d_layers=1, d_ff=128, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, output_enc=False, do_predict=False, seg_len=24, win_size=2, num_routers=10, class_strategy='projection', subgraph_size=20, in_dim=1, gpt_layers=6, tmax=10, patch_size=16, num_workers=0, itr=1, train_epochs=10, begin_valid_epoch=0, batch_size=32, patience=3, optim='AdamW', learning_rate=0.003, des='test', loss='mse', lradj='type3', use_amp=False, pct_start=0.3, warmup_epochs=5, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False, local_rank=-1, buffer_size=500, mini_batch=5, lambda_period=0.1, whole_model=False, continual=False, ensemble=False, enc_in=7, c_out=7, data_path='ETTh2.csv', dec_in=7, data='ETTh2', borders=([0, 2544, 3264], [2880, 3600, 14400]), model_id='ETTh2_336_48_iTransformer', timeenc=1, find_unused_parameters=False)
Seed: 2021
Use GPU: cuda:0
Load checkpoints from ./checkpoints/ETTh2_336_48_iTransformer_online_ftM_sl336_ll48_pl48_lr0.0001_dm128_nh8_el2_dl1_df128_fc3_ebtimeF_dtTrue_test_0/checkpoint.pth
Learning rate of model_optim is 0.0001
Number of Params: 248752 -> 465008 (+216256)
Proceed(
  (backbone): Model(
    (enc_embedding): DataEmbedding_inverted(
      (value_embedding): Linear(in_features=336, out_features=128, bias=True)
      (dropout): Dropout(p=0.05, inplace=False)
    )
    (encoder): Encoder(
      (attn_layers): ModuleList(
        (0-1): 2 x EncoderLayer(
          (attention): AttentionLayer(
            (inner_attention): FullAttention(
              (dropout): Dropout(p=0.05, inplace=False)
            )
            (query_projection): Linear(in_features=128, out_features=128, bias=True)
            (key_projection): Linear(in_features=128, out_features=128, bias=True)
            (value_projection): Linear(in_features=128, out_features=128, bias=True)
            (out_projection): Linear(in_features=128, out_features=128, bias=True)
          )
          (conv1): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
          (conv2): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.05, inplace=False)
        )
      )
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (projector): Linear(in_features=128, out_features=48, bias=True)
  )
  (generator): AdaptGenerator(
    (bottlenecks): ModuleDict(
      (value_embedding_592): Bottleneck(
        (activation): Sigmoid()
        (biases): ParameterList(
            (0): Parameter containing: [torch.float32 of size 1x1x48]
            (1): Parameter containing: [torch.float32 of size 1x1x592]
        )
        (weights): ParameterList(
            (0): Object of type: Linear
            (1): Parameter containing: [torch.float32 of size 1x1x592x48]
          (0): Linear(in_features=50, out_features=48, bias=False)
        )
      )
      (query_projection_384): Bottleneck(
        (activation): Sigmoid()
        (biases): ParameterList(
            (0): Parameter containing: [torch.float32 of size 2x1x48]
            (1): Parameter containing: [torch.float32 of size 2x1x384]
        )
        (weights): ParameterList(
            (0): Object of type: Linear
            (1): Parameter containing: [torch.float32 of size 1x1x384x48]
          (0): Linear(in_features=50, out_features=48, bias=False)
        )
      )
      (key_projection_384): Bottleneck(
        (activation): Sigmoid()
        (biases): ParameterList(
            (0): Parameter containing: [torch.float32 of size 2x1x48]
            (1): Parameter containing: [torch.float32 of size 2x1x384]
        )
        (weights): ParameterList(
            (0): Object of type: Linear
            (1): Parameter containing: [torch.float32 of size 1x1x384x48]
          (0): Linear(in_features=50, out_features=48, bias=False)
        )
      )
      (value_projection_384): Bottleneck(
        (activation): Sigmoid()
        (biases): ParameterList(
            (0): Parameter containing: [torch.float32 of size 2x1x48]
            (1): Parameter containing: [torch.float32 of size 2x1x384]
        )
        (weights): ParameterList(
            (0): Object of type: Linear
            (1): Parameter containing: [torch.float32 of size 1x1x384x48]
          (0): Linear(in_features=50, out_features=48, bias=False)
        )
      )
      (out_projection_384): Bottleneck(
        (activation): Sigmoid()
        (biases): ParameterList(
            (0): Parameter containing: [torch.float32 of size 2x1x48]
            (1): Parameter containing: [torch.float32 of size 2x1x384]
        )
        (weights): ParameterList(
            (0): Object of type: Linear
            (1): Parameter containing: [torch.float32 of size 1x1x384x48]
          (0): Linear(in_features=50, out_features=48, bias=False)
        )
      )
      (conv1_384): Bottleneck(
        (activation): Sigmoid()
        (biases): ParameterList(
            (0): Parameter containing: [torch.float32 of size 2x1x48]
            (1): Parameter containing: [torch.float32 of size 2x1x384]
        )
        (weights): ParameterList(
            (0): Object of type: Linear
            (1): Parameter containing: [torch.float32 of size 1x1x384x48]
          (0): Linear(in_features=50, out_features=48, bias=False)
        )
      )
      (conv2_384): Bottleneck(
        (activation): Sigmoid()
        (biases): ParameterList(
            (0): Parameter containing: [torch.float32 of size 2x1x48]
            (1): Parameter containing: [torch.float32 of size 2x1x384]
        )
        (weights): ParameterList(
            (0): Object of type: Linear
            (1): Parameter containing: [torch.float32 of size 1x1x384x48]
          (0): Linear(in_features=50, out_features=48, bias=False)
        )
      )
      (projector_224): Bottleneck(
        (activation): Sigmoid()
        (biases): ParameterList(
            (0): Parameter containing: [torch.float32 of size 1x1x48]
            (1): Parameter containing: [torch.float32 of size 1x1x224]
        )
        (weights): ParameterList(
            (0): Object of type: Linear
            (1): Parameter containing: [torch.float32 of size 1x1x224x48]
          (0): Linear(in_features=50, out_features=48, bias=False)
        )
      )
    )
    (loras): ModuleDict()
  )
  (mlp1): Sequential(
    (0): Transpose()
    (1): Linear(in_features=336, out_features=50, bias=True)
    (2): GELU(approximate='none')
    (3): Linear(in_features=50, out_features=50, bias=True)
  )
  (mlp2): Sequential(
    (0): Transpose()
    (1): Linear(in_features=384, out_features=50, bias=True)
    (2): GELU(approximate='none')
    (3): Linear(in_features=50, out_features=50, bias=True)
  )
)
train 2497
Checkpoints in ./checkpoints/ETTh2_336_48_iTransformer_proceed_fulltune_type3_down_up_btl48_ema0_mid50_share_ftM_sl336_ll48_pl48_lr0.003_dm128_nh8_el2_dl1_df128_fc3_ebtimeF_dtTrue_test_0/checkpoint.pth
>>>>>>>start training : ETTh2_336_48_iTransformer_proceed_fulltune_type3_down_up_btl48_ema0_mid50_share_ftM_sl336_ll48_pl48_lr0.003_dm128_nh8_el2_dl1_df128_fc3_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
val 673
Epoch: 1, Steps: 78 | Train Loss: 0.4582858 Vali Loss: 0.8823831
Epoch: 1 cost time: 39.699634075164795
Updating learning rate to 0.003
Epoch: 2, Steps: 78 | Train Loss: 0.3975021 Vali Loss: 0.8486325
Epoch: 2 cost time: 34.61425065994263
Updating learning rate to 0.003
Epoch: 3, Steps: 78 | Train Loss: 0.3699415 Vali Loss: 0.8887973
EarlyStopping counter: 1 out of 3
Epoch: 3 cost time: 31.578040838241577
Updating learning rate to 0.003
Epoch: 4, Steps: 78 | Train Loss: 0.3343231 Vali Loss: 0.8503342
EarlyStopping counter: 2 out of 3
Epoch: 4 cost time: 32.0859808921814
Updating learning rate to 0.0027
Epoch: 5, Steps: 78 | Train Loss: 0.3102885 Vali Loss: 0.9056623
EarlyStopping counter: 3 out of 3
Epoch: 5 cost time: 32.353519678115845
Early stopping
Best Valid MSE: 0.848632461948944
Save checkpoint to ./checkpoints/ETTh2_336_48_iTransformer_proceed_fulltune_type3_down_up_btl48_ema0_mid50_share_ftM_sl336_ll48_pl48_lr0.003_dm128_nh8_el2_dl1_df128_fc3_ebtimeF_dtTrue_test_0
Adjust learning rate of model_optim to 3e-05
>>>>>>>testing : ETTh2_336_48_iTransformer_proceed_fulltune_type3_down_up_btl48_ema0_mid50_share_ftM_sl336_ll48_pl48_lr0.003_dm128_nh8_el2_dl1_df128_fc3_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
val 720

  0%|          | 0/720 [00:00<?, ?it/s]
 16%|█▋        | 117/720 [00:10<00:51, 11.64it/s]
 32%|███▎      | 234/720 [00:20<00:43, 11.27it/s]
 48%|████▊     | 345/720 [00:30<00:33, 11.05it/s]
 64%|██████▍   | 462/720 [00:41<00:22, 11.28it/s]
 80%|████████  | 579/720 [00:51<00:12, 11.09it/s]
 96%|█████████▋| 693/720 [01:01<00:02, 11.19it/s]
100%|██████████| 720/720 [01:04<00:00, 11.22it/s]
Trainable Params: 254176 (102.2%)
test 10753

  0%|          | 0/10753 [00:00<?, ?it/s]
  2%|▏         | 243/10753 [00:10<07:13, 24.23it/s]
  5%|▍         | 486/10753 [00:20<07:08, 23.97it/s]
  7%|▋         | 724/10753 [00:30<07:13, 23.11it/s]
  9%|▉         | 946/10753 [00:42<07:38, 21.39it/s]
 11%|█         | 1178/10753 [00:52<07:15, 21.99it/s]
 13%|█▎        | 1418/10753 [01:02<06:52, 22.62it/s]
 15%|█▌        | 1658/10753 [01:12<06:35, 23.02it/s]
 18%|█▊        | 1897/10753 [01:22<06:20, 23.29it/s]
 20%|█▉        | 2137/10753 [01:32<06:06, 23.49it/s]
 22%|██▏       | 2377/10753 [01:42<05:54, 23.62it/s]
 24%|██▍       | 2617/10753 [01:52<05:43, 23.70it/s]
 27%|██▋       | 2856/10753 [02:02<05:32, 23.75it/s]
 29%|██▉       | 3095/10753 [02:13<05:24, 23.58it/s]
 31%|███       | 3328/10753 [02:23<05:16, 23.43it/s]
 33%|███▎      | 3561/10753 [02:33<05:07, 23.39it/s]
 35%|███▌      | 3794/10753 [02:43<04:58, 23.35it/s]
 38%|███▊      | 4034/10753 [02:53<04:45, 23.54it/s]
 40%|███▉      | 4274/10753 [03:03<04:33, 23.65it/s]
 42%|████▏     | 4514/10753 [03:13<04:22, 23.74it/s]
 44%|████▍     | 4754/10753 [03:23<04:12, 23.79it/s]
 46%|████▋     | 4994/10753 [03:33<04:01, 23.83it/s]
 49%|████▊     | 5234/10753 [03:43<03:51, 23.84it/s]
 51%|█████     | 5473/10753 [03:53<03:41, 23.84it/s]
 53%|█████▎    | 5713/10753 [04:03<03:31, 23.87it/s]
 55%|█████▌    | 5954/10753 [04:13<03:20, 23.91it/s]
 58%|█████▊    | 6195/10753 [04:23<03:10, 23.89it/s]
 60%|█████▉    | 6434/10753 [04:33<03:00, 23.89it/s]
 62%|██████▏   | 6673/10753 [04:43<02:50, 23.89it/s]
 64%|██████▍   | 6912/10753 [04:53<02:40, 23.88it/s]
 67%|██████▋   | 7151/10753 [05:03<02:30, 23.87it/s]
 69%|██████▊   | 7390/10753 [05:13<02:20, 23.87it/s]
 71%|███████   | 7629/10753 [05:23<02:10, 23.86it/s]
 73%|███████▎  | 7871/10753 [05:33<02:00, 23.95it/s]
 75%|███████▌  | 8113/10753 [05:43<01:50, 23.93it/s]
 78%|███████▊  | 8352/10753 [05:53<01:40, 23.91it/s]
 80%|███████▉  | 8591/10753 [06:03<01:30, 23.89it/s]
 82%|████████▏ | 8831/10753 [06:13<01:20, 23.92it/s]
 84%|████████▍ | 9073/10753 [06:24<01:10, 23.98it/s]
 87%|████████▋ | 9315/10753 [06:34<00:59, 23.99it/s]
 89%|████████▉ | 9556/10753 [06:44<00:49, 24.00it/s]
 91%|█████████ | 9797/10753 [06:54<00:39, 24.02it/s]
 93%|█████████▎| 10038/10753 [07:04<00:30, 23.74it/s]
 96%|█████████▌| 10270/10753 [07:14<00:20, 23.55it/s]
 98%|█████████▊| 10505/10753 [07:24<00:10, 23.52it/s]
100%|█████████▉| 10742/10753 [07:34<00:00, 23.55it/s]
100%|██████████| 10753/10753 [07:35<00:00, 23.63it/s]
mse:3.9197689859226412, mae:0.7537073473547665
{'mae': [0.7537073473547665, 0.0], 'mse': [3.9197689859226412, 0.0]}
